{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cde7744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import useful libriaries.\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.python.ops.math_ops import reduce_prod\n",
    "from sklearn.model_selection import train_test_split\n",
    "from LoadFaceData import load_dataset, resize_image, IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f365a607",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787, 64, 64, 3)\n",
      "['Jiahao Wang', 'Xingda Zhou', 'Zhongen Qin', 'Yuxi Wu', 'Yuan Li', 'Jufeng Yang']\n",
      "face_num: 6\n",
      "contrast_table: {0: 'Jiahao Wang', 1: 'Xingda Zhou', 2: 'Zhongen Qin', 3: 'Yuxi Wu', 4: 'Yuan Li', 5: 'Jufeng Yang'}\n",
      "550 train samples\n",
      "237 valid samples\n",
      "394 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 3, 256)            4457472   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3, 128)            197120    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 3, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 3, 64)             49408     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3, 64)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 4,737,926\n",
      "Trainable params: 4,737,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 550 samples, validate on 237 samples\n",
      "Epoch 1/20\n",
      "550/550 [==============================] - 50s 92ms/sample - loss: 1.7677 - accuracy: 0.2255 - val_loss: 1.7604 - val_accuracy: 0.3713\n",
      "Epoch 2/20\n",
      "550/550 [==============================] - 42s 76ms/sample - loss: 1.6514 - accuracy: 0.3200 - val_loss: 1.9385 - val_accuracy: 0.3966\n",
      "Epoch 3/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 1.4144 - accuracy: 0.3945 - val_loss: 1.1164 - val_accuracy: 0.4346\n",
      "Epoch 4/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 1.1257 - accuracy: 0.4600 - val_loss: 0.9688 - val_accuracy: 0.5485\n",
      "Epoch 5/20\n",
      "550/550 [==============================] - 42s 76ms/sample - loss: 1.1657 - accuracy: 0.4455 - val_loss: 0.8686 - val_accuracy: 0.5485\n",
      "Epoch 6/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.9917 - accuracy: 0.5182 - val_loss: 0.7637 - val_accuracy: 0.6540\n",
      "Epoch 7/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.9522 - accuracy: 0.5673 - val_loss: 0.7583 - val_accuracy: 0.6709\n",
      "Epoch 8/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.7856 - accuracy: 0.6527 - val_loss: 0.6403 - val_accuracy: 0.6709\n",
      "Epoch 9/20\n",
      "550/550 [==============================] - 42s 76ms/sample - loss: 0.6966 - accuracy: 0.6473 - val_loss: 0.5607 - val_accuracy: 0.6456\n",
      "Epoch 10/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.6482 - accuracy: 0.6745 - val_loss: 0.5059 - val_accuracy: 0.6709\n",
      "Epoch 11/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.6137 - accuracy: 0.7236 - val_loss: 0.5558 - val_accuracy: 0.6793\n",
      "Epoch 12/20\n",
      "550/550 [==============================] - 43s 78ms/sample - loss: 0.8089 - accuracy: 0.6582 - val_loss: 0.5828 - val_accuracy: 0.7215\n",
      "Epoch 13/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.5964 - accuracy: 0.7018 - val_loss: 0.5025 - val_accuracy: 0.6709\n",
      "Epoch 14/20\n",
      "550/550 [==============================] - 42s 76ms/sample - loss: 0.9305 - accuracy: 0.6145 - val_loss: 0.5507 - val_accuracy: 0.6709\n",
      "Epoch 15/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.6262 - accuracy: 0.7036 - val_loss: 1.4459 - val_accuracy: 0.5316\n",
      "Epoch 16/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.7225 - accuracy: 0.6873 - val_loss: 0.4923 - val_accuracy: 0.6709\n",
      "Epoch 17/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.5432 - accuracy: 0.7455 - val_loss: 0.4202 - val_accuracy: 0.8439\n",
      "Epoch 18/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.4976 - accuracy: 0.8000 - val_loss: 0.2946 - val_accuracy: 0.8397\n",
      "Epoch 19/20\n",
      "550/550 [==============================] - 43s 77ms/sample - loss: 0.4815 - accuracy: 0.8327 - val_loss: 0.2887 - val_accuracy: 0.8397\n",
      "Epoch 20/20\n",
      "550/550 [==============================] - 42s 77ms/sample - loss: 0.4074 - accuracy: 0.8455 - val_loss: 0.2555 - val_accuracy: 0.9325\n",
      "WARNING:tensorflow:From D:\\Anaconda Python\\envs\\tensorflow2-cpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: ./model\\assets\n",
      "394/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 2s 4ms/sample - loss: 0.1711 - accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.92%\n"
     ]
    }
   ],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, path_name):\n",
    "        # Test dataset\n",
    "        self.train_images = None\n",
    "        self.train_labels = None\n",
    "\n",
    "        # Validation dataset\n",
    "        self.valid_images = None\n",
    "        self.valid_labels = None\n",
    "\n",
    "        # Test dataset\n",
    "        self.test_images = None\n",
    "        self.test_labels = None\n",
    "\n",
    "        # The path of dataset\n",
    "        self.path_name = path_name\n",
    "\n",
    "        # The shape of input data of CNN or LSTM\n",
    "        self.input_shape = None\n",
    "        \n",
    "        #The number of dataset label.\n",
    "        self.nb_classes = None\n",
    "\n",
    "    # Load the dataset and preprocess pictures into suitable dim for CNN or LSTM\n",
    "    def load(self, img_rows=IMAGE_SIZE, img_cols=IMAGE_SIZE,\n",
    "             img_channels=3):\n",
    "        \n",
    "        # Define some useful variables\n",
    "        image = []\n",
    "        labels = []\n",
    "        face_num = []\n",
    "        \n",
    "        #Load basical dataset and return it into variables \n",
    "        images, labels, face_num = load_dataset(self.path_name)\n",
    "        self.nb_classes = face_num\n",
    "        \n",
    "        # Use the split function to separate the basical picture into different array for furture test and validation\n",
    "        train_images, valid_images, train_labels, valid_labels = train_test_split(images, labels, test_size=0.3,\n",
    "                                                                                  random_state=random.randint(0, 100))\n",
    "        _, test_images, _, test_labels = train_test_split(images, labels, test_size=0.5,\n",
    "                                                          random_state=random.randint(0, 100))\n",
    "\n",
    "        # if the data dim is 'th'，the data qualitu is ：channels,rows,cols，if not:rows,cols,channels\n",
    "        # Reshape all dataset including training, validation, test images into a special shape according the keras specification.\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_channels, img_rows, img_cols)\n",
    "            self.input_shape = (img_channels, img_rows, img_cols)\n",
    "        else:\n",
    "            train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            valid_images = valid_images.reshape(valid_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            test_images = test_images.reshape(test_images.shape[0], img_rows, img_cols, img_channels)\n",
    "            self.input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "            # Show the number of training, valid, test image.\n",
    "            print(train_images.shape[0], 'train samples')\n",
    "            print(valid_images.shape[0], 'valid samples')\n",
    "            print(test_images.shape[0], 'test samples')\n",
    "\n",
    "            # Convert the labels into one-hot code.\n",
    "            train_labels = utils.to_categorical(train_labels, self.nb_classes)\n",
    "            valid_labels = utils.to_categorical(valid_labels, self.nb_classes)\n",
    "            test_labels = utils.to_categorical(test_labels, self.nb_classes)\n",
    "            \n",
    "            # Change the data into float type.\n",
    "            train_images = train_images.astype('float32')\n",
    "            valid_images = valid_images.astype('float32')\n",
    "            test_images = test_images.astype('float32')\n",
    "\n",
    "            # Nomalization all data in to 0 - 1.\n",
    "            train_images /= 255\n",
    "            valid_images /= 255\n",
    "            test_images /= 255\n",
    "            \n",
    "            # Assign all image and label data to class variables\n",
    "            self.train_images = train_images\n",
    "            self.valid_images = valid_images\n",
    "            self.test_images = test_images\n",
    "            self.train_labels = train_labels\n",
    "            self.valid_labels = valid_labels\n",
    "            self.test_labels = test_labels\n",
    "\n",
    "\n",
    "# LSTM model\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    " \n",
    "    # Built a model\n",
    "    def build_model(self, dataset, nb_classes):\n",
    "       \n",
    "        # Use a list to discribe a LSTM layers.\n",
    "        # Here contains 3 layers, first layter contain 256 cells, second layer contain 128 cells, third layer 64 cells.\n",
    "        # The timestep is 3(the BGR channel number), batch-size is size of grey picture(64*64).\n",
    "        # Return a sequences tensor.\n",
    "        # Each LSTM layer followed by a dropout layer, which used to decrease over-fit.Here it give up 20% cells.\n",
    "        # Use a Flatten layer to conbine all layers output.with a 256 neurons dense layer to train the net.\n",
    "        # Use a dense layer to output a face number classes.\n",
    "        LSTM_layers = [\n",
    "            \n",
    "            LSTM(256, input_shape = (3, IMAGE_SIZE*IMAGE_SIZE), return_sequences = True),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            LSTM(128, input_shape = (3, IMAGE_SIZE*IMAGE_SIZE), return_sequences = True),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            LSTM(64, input_shape = (3, IMAGE_SIZE*IMAGE_SIZE), return_sequences = True),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            LSTM(32),\n",
    "            Dropout(0.2),\n",
    "            \n",
    "            Flatten(),\n",
    "            #Dense(256, activation = tf.nn.relu),\n",
    "            #Dropout(0.25),\n",
    "            Dense(128, activation = tf.nn.relu),\n",
    "            Dropout(0.25),\n",
    "            Dense(128, activation = tf.nn.relu),\n",
    "            Dropout(0.25),\n",
    "            \n",
    "            Dense(nb_classes, activation = tf.nn.softmax)\n",
    "              \n",
    "        ]\n",
    "        \n",
    "        self.model = Sequential(LSTM_layers)\n",
    "        \n",
    "        self.model.summary()\n",
    "           \n",
    "        \n",
    "    # Train the LSTM model\n",
    "    def train(self, dataset, batch_size=20, nb_epoch=20, data_augmentation=True):\n",
    "        \n",
    "        # Define a SGD optimizer.\n",
    "        sgd = SGD(learning_rate=0.0007, decay=1e-6,\n",
    "                  momentum=0.9, nesterov=True)\n",
    "        \n",
    "        # Define a Adam optimazer\n",
    "        adam = Adam(learning_rate = 0.0007, decay = 1e-6)\n",
    "        \n",
    "        # compile a model, loss funtion use the categorical_crossentropy.\n",
    "        self.model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])  # 完成实际的模型配置工作\n",
    "\n",
    "        # Reshape the dataset shape into the LSTM required.The shape here is [image numbers, channels = 3, imageshape = 64*64]\n",
    "        dataset.train_images = dataset.train_images.reshape(dataset.train_images.shape[0], dataset.train_images.shape[3], \n",
    "                                                                dataset.train_images.shape[1]*dataset.train_images.shape[2]) \n",
    "        dataset.valid_images = dataset.valid_images.reshape(dataset.valid_images.shape[0], dataset.valid_images.shape[3], \n",
    "                                                                dataset.valid_images.shape[1]*dataset.valid_images.shape[2])\n",
    "        dataset.test_images = dataset.test_images.reshape(dataset.test_images.shape[0], dataset.test_images.shape[3], \n",
    "                                                                dataset.test_images.shape[1]*dataset.test_images.shape[2])\n",
    "        # Train and fit a model    \n",
    "        self.model.fit(dataset.train_images, dataset.train_labels,\n",
    "                                     validation_data=(dataset.valid_images, dataset.valid_labels),\n",
    "                                     steps_per_epoch=len(dataset.train_images),\n",
    "                                     epochs=nb_epoch)\n",
    "    \n",
    "    # Define a model parameter store path \n",
    "    MODEL_PATH = './model'\n",
    "    \n",
    "    # Save the model parameter in the defined path\n",
    "    def save_model(self, file_path=MODEL_PATH):\n",
    "        self.model.save(file_path)\n",
    "    \n",
    "    #Load a model from the defined path\n",
    "    def load_model(self, file_path=MODEL_PATH):\n",
    "        self.model = load_model(file_path)\n",
    "\n",
    "    # Evaluate a model from the defined path using the dataset\n",
    "    def evaluate(self, dataset):\n",
    "        score = self.model.evaluate(dataset.test_images, dataset.test_labels, verbose=1)\n",
    "        print(\"%s: %.2f%%\" % (self.model.metrics_names[1], score[1] * 100))\n",
    "    \n",
    "    # Recognize the face\n",
    "    def face_predict(self, image):\n",
    "   \n",
    "        # Accordinf the Dim to reshape the image shape.\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            image = resize_image(image) \n",
    "            image = image.reshape((1, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "        else:\n",
    "            image = resize_image(image)\n",
    "            image = image.reshape((1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "         \n",
    "        # Reshape the shape in the same shape as LSTM input.\n",
    "        image = image.reshape(image.shape[0], image.shape[3], image.shape[1]*image.shape[2])    \n",
    "            \n",
    "        # Float and normalize the input.\n",
    "        image = image.astype('float32')\n",
    "        image /= 255\n",
    "        #print(image.shape)\n",
    "        \n",
    "        # Print the probability of name response the present face.\n",
    "        result_probability = self.model.predict(image)\n",
    "        print('result:', result_probability, max(result_probability[0]))\n",
    "\n",
    "        # Output the one-hot code and change it into the name od user.\n",
    "        result = self.model.predict(image)\n",
    "        result = np.argmax(result, axis=-1)\n",
    "\n",
    "        return max(result_probability[0]),result[0]\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = Dataset('./Facial data')\n",
    "    dataset.load()\n",
    "    model = Model()\n",
    "    model.build_model(dataset, dataset.nb_classes)\n",
    "    model.train(dataset)\n",
    "    model.save_model(file_path='./model')\n",
    "    model.evaluate(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cf5b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow2-CPU",
   "language": "python",
   "name": "tensorflow2-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
